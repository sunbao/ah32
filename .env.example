# Ah32 (阿蛤) backend environment example (DO NOT put real secrets here)
#
# Quick start (recommended):
# 1) Copy this file to `.env`
# 2) Only fill in `DEEPSEEK_API_KEY=...`
# 3) Start the app. Everything else has safe defaults.
#
# Notes:
# - Empty values (e.g. AH32_MEMORY_ROOT=) are treated as "unset" and will fall back to defaults.
# - If you deploy remotely, you may need to configure storage persistence + shared-path mapping.

# Server
AH32_SERVER_HOST=127.0.0.1
AH32_SERVER_PORT=5123

# Auth
# Local-only default: disable auth. If you enable it, set a strong API key.
AH32_ENABLE_AUTH=false
AH32_API_KEY=

# CORS (use JSON array format: ["*"] or ["http://localhost:3000"] or comma-separated: *,http://localhost:3000)
AH32_CORS_ALLOWED_ORIGINS=["*"]

# LLM / tracing (optional)
# Required for DeepSeek:
DEEPSEEK_API_KEY=
#
# Optional: if you use an OpenAI-compatible endpoint instead of DeepSeek, set:
AH32_OPENAI_API_KEY=
LANGSMITH_TRACING=
LANGSMITH_API_KEY=
LANGSMITH_ENDPOINT=
LANGSMITH_PROJECT=

# Models / runtime
AH32_LLM_MODEL=deepseek-reasoner
AH32_LLM_TEMPERATURE=0.2
#
# LLM Provider routing (optional):
# - Default behavior: if model name contains "deepseek", use https://api.deepseek.com
# - To switch to any OpenAI-compatible endpoint (OpenAI / self-hosted gateway), set:
#   AH32_LLM_PROVIDER=openai-compatible
#   AH32_LLM_BASE_URL=https://your-gateway.example.com/v1
# Note: AH32_LLM_BASE_URL wins over auto-detection.
AH32_LLM_PROVIDER=
AH32_LLM_BASE_URL=

# JS 宏（WPS TaskPane）专用：默认更偏向“快 + 稳”，避免宏生成/修复拖慢整体体验
# - 未配置时：如果 AH32_LLM_MODEL=deepseek-reasoner，则宏默认用 deepseek-chat；温度默认 0.2
# - 如需更高成功率但更慢：可把 AH32_JS_MACRO_MODEL 也设为 deepseek-reasoner
#AH32_JS_MACRO_MODEL=deepseek-chat
#AH32_JS_MACRO_TEMPERATURE=0.2
AH32_EMBEDDING_MODEL=BAAI/bge-m3
AH32_ENABLE_GPU=true
AH32_GPU_DEVICE=auto
HF_HUB_OFFLINE=1
TRANSFORMERS_OFFLINE=1

# Storage / persistence
# For remote deployments, mount these folders to a persistent volume.
# Defaults (when unset): ./storage and ./storage/memory (under the repo/runtime root).
AH32_STORAGE_ROOT=storage
AH32_MEMORY_ROOT=storage/memory

# JS macro quality memory (cross-session learning; compact Top-K rules to reduce repeated JS errors)
# Default persist file: <AH32_MEMORY_ROOT>/code_quality_memory.json
# Optional override:
# AH32_CODE_QUALITY_MEMORY_PATH=
# Debug option (sync write after each record; slower but safer if you suspect crashes):
# AH32_CODE_QUALITY_MEMORY_SYNC_SAVE=false

# Shared-path mode (optional, enterprise): map client paths to backend-readable mounts.
# Format: "<clientPrefix>=><serverPrefix>" separated by ";" or newlines.
# Examples:
#   AH32_PATH_MAPPINGS=Z:\\share=>/mnt/share;\\\\server\\share\\=>/mnt/share/
AH32_PATH_MAPPINGS=

# Runtime extensions
# - Skills: drop skill folders into this directory; backend hot-loads them every request.
# Default (when unset):
# - Windows: C:\\Users\\<YOU>\\Documents\\Ah32\\skills
# - macOS:   /Users/<YOU>/Documents/Ah32/skills
# - Linux:   /home/<YOU>/Documents/Ah32/skills
# If the OS "Documents" folder is not found, it falls back to the user's home dir.
AH32_SKILLS_DIR=
AH32_SKILLS_ENABLED=true
AH32_SKILLS_MAX_CHARS=12000

# - Per-conversation rule files (Claude.md-like): semicolon-separated paths (docx/txt/md).
#   Example: rules/office.md;C:/Docs/team-guide.docx
# Default (when unset): auto-discover from "<Documents>/Ah32/" in this order:
#   rules.docx, rules.md, 规则.docx, 规则.md, rules.txt, 规则.txt
AH32_CONVERSATION_RULE_FILES=
AH32_CONVERSATION_RULE_FILES_MAX_CHARS=12000

# Debug (admin master switches)
# - OFF: frontend user toggles (show_thoughts/show_rag) have no effect.
# - ON : frontend can enable per-session debug display (recommended only for internal/dev).
AH32_EXPOSE_AGENT_THOUGHTS=false
## Debug only: stream a compact RAG hit summary (event: rag)
AH32_EXPOSE_RAG_HITS=false
# Debug only: dump JS macro inputs/outputs to `storage/macro_debug/` for troubleshooting.
AH32_SAVE_MACRO_DEBUG=false
LOG_LEVEL=INFO
RELOAD=false
