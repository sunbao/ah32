"""é˜¿è›¤ï¼ˆAH32ï¼‰Agent åè°ƒå™¨ - ä¸“æ³¨äºä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼Œä¸åšå†³ç­–

æ ¹æ® docs/AH32_DESIGN.md è®¾è®¡ï¼š
- Agentæ„ŸçŸ¥ â†’ LLMå†³ç­– â†’ JSæ‰§è¡Œ
- Agentåªæ”¶é›†ä¸Šä¸‹æ–‡ï¼ˆæ–‡æ¡£çŠ¶æ€ã€å…‰æ ‡ã€é€‰åŒºç­‰ï¼‰
- LLMåŸºäºå®æ—¶ä¸Šä¸‹æ–‡è‡ªä¸»å†³ç­–ç”ŸæˆJSä»£ç 
- ä¸é¢„è®¾æ„å›¾åˆ†ç±»å’Œå·¥ä½œæµ
"""

from __future__ import annotations

import asyncio
import json
import logging
from typing import Any, Dict, List, Optional
from datetime import datetime

from langchain.agents import create_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain_core.language_models import BaseLanguageModel
from langchain_core.tools import BaseTool

from . import get_all_tools
from ah32.services.models import load_llm
from ah32.config import settings

logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰ - æé«˜ä»£ç å¯ç»´æŠ¤æ€§
DEFAULT_SESSION_ID = "default_session"
MAX_CONVERSATION_HISTORY = 20
DEFAULT_FONT = {"name": "å®‹ä½“", "size": 12}


class Ah32Coordinator:
    """Ah32 Agentåè°ƒå™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å·¥å…·å’Œäº¤äº’ï¼ˆAgenticæ¨¡å¼ï¼‰"""

    def __init__(self, vector_store=None):
        self.llm: Optional[BaseLanguageModel] = None
        self.tools: List[BaseTool] = []
        self.agent_executor: Optional[Any] = None
        self.conversation_history: List[BaseMessage] = []
        self.conversation_id: str = DEFAULT_SESSION_ID
        self.is_monitoring = False
        self.monitoring_task = None
        self._pending_changes: List[Dict] = []  # å¾…å¤„ç†çš„å˜åŒ–é€šçŸ¥
        self.vector_store = vector_store  # å‘é‡å­˜å‚¨å®ä¾‹

        # å»¶è¿Ÿåˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆé¿å…åœ¨__init__ä¸­è°ƒç”¨formatï¼‰
        self._system_prompt_created = False

    def _create_system_prompt(self, context: Dict[str, Any] = None) -> str:
        """åˆ›å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆå¢å¼ºç‰ˆï¼Œå……åˆ†åˆ©ç”¨æ‰€æœ‰æ„ŸçŸ¥æ•°æ®ï¼‰"""
        if context is None:
            context = {}

        return """ä½ æ˜¯é˜¿è›¤ï¼ˆAH32ï¼‰æ™ºèƒ½åŠå…¬åŠ©æ‰‹ï¼Œæ ¸å¿ƒèƒ½åŠ›æ˜¯æ ¹æ®å®Œæ•´çš„å®æ—¶æ„ŸçŸ¥æ•°æ®ç”Ÿæˆå¯æ‰§è¡Œçš„ WPS JS å®ä»£ç ã€‚

èŒè´£åˆ†ç¦»ï¼š
- Agentæ„ŸçŸ¥ï¼šæ”¶é›†å®Œæ•´çš„æ–‡æ¡£çŠ¶æ€ï¼ˆå…‰æ ‡ã€é€‰åŒºã€ç»“æ„ã€æ ¼å¼ã€è´¨é‡åˆ†æã€æ™ºèƒ½å»ºè®®ï¼‰
- LLMå†³ç­–ï¼šåŸºäºå®Œæ•´æ„ŸçŸ¥æ•°æ®è‡ªä¸»å†³ç­–ç”ŸæˆJSä»£ç 
- JSæ‰§è¡Œï¼šæ“ä½œWPSæ–‡æ¡£

æ„ŸçŸ¥ç»´åº¦ï¼š
1. åŸºç¡€æ„ŸçŸ¥ï¼šæ–‡æ¡£ä¿¡æ¯ã€å…‰æ ‡ä½ç½®ã€é€‰åŒºå†…å®¹ã€ç»“æ„ä¿¡æ¯ã€æ ¼å¼çŠ¶æ€
2. è¯­ä¹‰ç†è§£ï¼šè¯­ä¹‰ç« èŠ‚è¯†åˆ«ã€æ–‡æ¡£ç±»å‹åˆ†æã€ä»»åŠ¡ç±»å‹æ¨æ–­
3. è´¨é‡åˆ†æï¼šå¯è¯»æ€§è¯„åˆ†ã€é€»è¾‘æµç¨‹ã€å®Œæ•´æ€§æ£€æŸ¥ã€æ ¼å¼é—®é¢˜æ£€æµ‹
4. æ™ºèƒ½å»ºè®®ï¼šå†…å®¹å»ºè®®ã€æ ¼å¼æ¨èã€æ•ˆç‡æç¤º
5. å®æ—¶çŠ¶æ€ï¼šæ–‡æ¡£å˜åŒ–ã€ç”¨æˆ·è¡Œä¸ºã€æ€§èƒ½æ•°æ®ã€é”™è¯¯æ¢å¤

å·¥ä½œæµç¨‹ï¼š
1. åˆ†æå®Œæ•´æ„ŸçŸ¥æ•°æ®ï¼ˆåŒ…å«è´¨é‡åˆ†æå’Œæ™ºèƒ½å»ºè®®ï¼‰
2. åŸºäºè¯­ä¹‰ç†è§£å’Œä»»åŠ¡ç±»å‹è‡ªä¸»å†³ç­–å¤„ç†ç­–ç•¥
3. ç”Ÿæˆå¯æ‰§è¡Œçš„WPS JSå®ä»£ç 
4. ä»£ç æ ¼å¼ï¼š```js\\nfunction Xxx() {\\n    // JSå®ä»£ç \\n}\\n```

è¯·å……åˆ†åˆ©ç”¨æ‰€æœ‰æ„ŸçŸ¥æ•°æ®ï¼Œæä¾›æ™ºèƒ½åŒ–çš„åŠå…¬åŠ©æ‰‹åŠŸèƒ½ã€‚"""

    def _format_tools_for_prompt(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨ä¾›æç¤ºè¯ä½¿ç”¨"""
        if not self.tools:
            return "æ— å¯ç”¨å·¥å…·"
        
        tool_descriptions = []
        for tool in self.tools:
            tool_name = getattr(tool, 'name', tool.__class__.__name__)
            tool_description = getattr(tool, 'description', 'æ— æè¿°')
            tool_descriptions.append(f"- {tool_name}: {tool_description}")
        
        return "\n".join(tool_descriptions)

    def _get_default_context(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤ä¸Šä¸‹æ–‡ï¼ˆå‡å°‘ç¡¬ç¼–ç ï¼‰"""
        return {
            "document_state": {"name": "æœªçŸ¥æ–‡æ¡£", "total_lines": 0},
            "cursor_position": {"line": 1, "column": 1},
            "selection": {"is_empty": True, "text": None},
            "structure": {"headings": [], "tables": [], "images": []},
            "format_state": {"font": DEFAULT_FONT, "paragraph": {"alignment": 0}}
        }

    async def _handle_at_references(self, user_input: str) -> Dict[str, Any]:
        """å¤„ç†@å¼•ç”¨

        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬

        Returns:
            @å¼•ç”¨å¤„ç†ç»“æœ
        """
        try:
            logger.debug("å¼€å§‹å¤„ç†@å¼•ç”¨...")

            # å¯¼å…¥@å¼•ç”¨å¤„ç†å™¨
            from ah32.services.at_reference_handler import AtReferenceHandler
            from ah32.knowledge.store import LocalVectorStore

            # è·å–å‘é‡å­˜å‚¨å®ä¾‹
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿vector_storeå¯ç”¨
            vector_store = getattr(self, 'vector_store', None)
            if not vector_store:
                logger.warning("å‘é‡å­˜å‚¨ä¸å¯ç”¨ï¼Œè·³è¿‡@å¼•ç”¨å¤„ç†")
                return {"paths": [], "processed": [], "errors": ["å‘é‡å­˜å‚¨ä¸å¯ç”¨"]}

            # åˆ›å»º@å¼•ç”¨å¤„ç†å™¨
            at_handler = AtReferenceHandler(vector_store)

            # å¤„ç†@å¼•ç”¨
            result = await at_handler.handle(user_input)

            logger.debug("@å¼•ç”¨å¤„ç†å®Œæˆ")
            return result

        except ImportError as e:
            logger.warning(f"@å¼•ç”¨å¤„ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
            return {"paths": [], "processed": [], "errors": [f"å¯¼å…¥é”™è¯¯: {str(e)}"]}
        except Exception as e:
            logger.error(f"@å¼•ç”¨å¤„ç†å¤±è´¥: {e}")
            logger.debug(f"@å¼•ç”¨å¤„ç†é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}", exc_info=True)
            return {"paths": [], "processed": [], "errors": [str(e)]}

    def _create_agent(self):
        """åˆ›å»ºLangChain Agentï¼ˆé€‚é…æ–°ç‰ˆæœ¬APIï¼‰"""
        if not self.llm:
            self.llm = load_llm(settings)

        if not self.tools:
            self.tools = get_all_tools()

        # å»¶è¿Ÿåˆ›å»ºç³»ç»Ÿæç¤ºè¯
        if not self._system_prompt_created:
            self.system_prompt = self._create_system_prompt()
            self._system_prompt_created = True

        # åˆ›å»ºAgentï¼ˆé€‚é…æ–°ç‰ˆæœ¬APIï¼‰
        self.agent_executor = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt=self.system_prompt
        )

        return self.agent_executor

    async def gather_context(self, frontend_context: Dict[str, Any] = None, user_input: str = None) -> Dict[str, Any]:
        """æ„ŸçŸ¥æ–‡æ¡£çŠ¶æ€ï¼ˆAgenticæ ¸å¿ƒï¼šå¯¹è¯è§¦å‘æ„ŸçŸ¥ â†’ ç«‹å³ä¼ ç»™LLMï¼‰

        Agenticè®¾è®¡ç†å¿µï¼š
        - ç”¨æˆ·å‘èµ·å¯¹è¯æ—¶æ„ŸçŸ¥æ–‡æ¡£çŠ¶æ€ï¼ˆå…‰æ ‡ã€é€‰åŒºã€ç»“æ„ã€æ ¼å¼ï¼‰
        - ç«‹å³ä¼ ç»™LLMè¿›è¡Œæ™ºèƒ½å†³ç­–
        - ç¼–è¾‘æ—¶é›¶å¹²æ‰°ï¼Œæ„ŸçŸ¥æ—¶é«˜æ•ˆå‡†ç¡®

        Args:
            frontend_context: å‰ç«¯æ„ŸçŸ¥çš„æ–‡æ¡£çŠ¶æ€ï¼ˆå…‰æ ‡ã€é€‰åŒºã€ç»“æ„ç­‰ï¼‰
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬ï¼Œç”¨äºå¤„ç†@å¼•ç”¨

        Returns:
            å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œç›´æ¥ä¼ ç»™LLM
        """
        try:
            logger.info("å¼€å§‹Agenticæ„ŸçŸ¥æ–‡æ¡£çŠ¶æ€...")

            # å¦‚æœæœ‰å‰ç«¯ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨çœŸå®æ„ŸçŸ¥ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤ä¸Šä¸‹æ–‡
            if frontend_context:
                # âœ… ä½¿ç”¨å‰ç«¯æ„ŸçŸ¥çš„å®Œæ•´æ–‡æ¡£çŠ¶æ€ï¼ˆåŒ…å«æ‰€æœ‰æ„ŸçŸ¥ç»´åº¦ï¼‰
                real_time_context = {
                    "document": {
                        "name": frontend_context.get("document", {}).get("name", "æœªå‘½å"),
                        "path": frontend_context.get("document", {}).get("path", ""),
                        "total_pages": frontend_context.get("document", {}).get("totalPages", 0),
                        "total_words": frontend_context.get("document", {}).get("totalWords", 0)
                    },
                    "cursor": frontend_context.get("cursor", {}),
                    "selection": frontend_context.get("selection", {}),
                    "structure": {
                        "headings": frontend_context.get("structure", {}).get("headings", []),
                        "tables": frontend_context.get("structure", {}).get("tables", 0),
                        "images": frontend_context.get("structure", {}).get("images", 0),
                        "current_section": frontend_context.get("structure", {}).get("currentSection", ""),
                        "semantic_sections": frontend_context.get("structure", {}).get("semanticSections", []),
                        "document_type": frontend_context.get("structure", {}).get("documentType", "report"),
                        "task_types": frontend_context.get("structure", {}).get("taskTypes", [])
                    },
                    "format": frontend_context.get("format", {}),
                    "quality_analysis": frontend_context.get("qualityAnalysis", {}),
                    "intelligent_suggestions": frontend_context.get("intelligentSuggestions", {}),
                    "realtime_status": frontend_context.get("realtime", {}),
                    "performance_data": frontend_context.get("performance", {}),
                    "user_behavior": frontend_context.get("behavior", {}),
                    "error_status": frontend_context.get("errors", {})
                }
                logger.info(f"[Agenticæ„ŸçŸ¥] æ”¶é›†æ–‡æ¡£çŠ¶æ€: {real_time_context['document']['name']}")
            else:
                # ä½¿ç”¨é»˜è®¤ä¸Šä¸‹æ–‡
                real_time_context = self._get_default_context()

            # å¤„ç†@å¼•ç”¨
            if user_input:
                logger.debug(f"å¼€å§‹å¤„ç†@å¼•ç”¨ï¼Œè¾“å…¥: {user_input[:100]}...")
                at_result = await self._handle_at_references(user_input)
                if at_result.get("processed"):
                    logger.info(f"æˆåŠŸå¤„ç† {len(at_result['processed'])} ä¸ª@å¼•ç”¨æ–‡ä»¶")
                    # å°†@å¼•ç”¨ç»“æœæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                    real_time_context["at_references"] = at_result
                else:
                    logger.debug("æœªæ‰¾åˆ°@å¼•ç”¨æˆ–å¤„ç†å¤±è´¥")
            else:
                logger.debug("æ— ç”¨æˆ·è¾“å…¥ï¼Œè·³è¿‡@å¼•ç”¨å¤„ç†")

            logger.info("Agenticæ„ŸçŸ¥å®Œæˆ")
            return {
                "success": True,
                "context": real_time_context,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"åŠ¨æ€æ„ŸçŸ¥å¤±è´¥: {e}")
            logger.debug(f"æ„ŸçŸ¥å¤±è´¥è¯¦æƒ…: {type(e).__name__}: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def chat(self, message: str, frontend_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Agenticæ„ŸçŸ¥å¼äº¤äº’å…¥å£ï¼ˆå¯¹è¯é©±åŠ¨æ„ŸçŸ¥ â†’ æ™ºèƒ½å†³ç­–ï¼‰

        Agenticè®¾è®¡æµç¨‹ï¼š
        1. ç”¨æˆ·å‘èµ·å¯¹è¯
        2. å‰ç«¯æ„ŸçŸ¥æ–‡æ¡£çŠ¶æ€ï¼ˆå…‰æ ‡ã€é€‰åŒºã€ç»“æ„ã€æ ¼å¼ï¼‰
        3. åç«¯æ”¶é›†å®Œæ•´ä¸Šä¸‹æ–‡
        4. LLMåŸºäºä¸Šä¸‹æ–‡è¿›è¡Œæ™ºèƒ½å†³ç­–
        5. è¿”å›ä¸ªæ€§åŒ–å“åº”

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            frontend_context: å‰ç«¯æ„ŸçŸ¥çš„æ–‡æ¡£çŠ¶æ€ï¼ˆå…‰æ ‡ã€é€‰åŒºã€ç»“æ„ç­‰ï¼‰

        Returns:
            LLMç”Ÿæˆçš„å“åº”å’Œä½¿ç”¨çš„ä¸Šä¸‹æ–‡
        """
        try:
            logger.info(f"å¤„ç†ç”¨æˆ·æ¶ˆæ¯: {message[:50]}...")

            # æ­¥éª¤1ï¼šAgenticæ„ŸçŸ¥æ–‡æ¡£çŠ¶æ€ï¼ˆå¯¹è¯é©±åŠ¨ï¼‰
            context_result = await self.gather_context(frontend_context, message)
            if context_result.get("success"):
                real_time_context = context_result["context"]
            else:
                # å¦‚æœåŠ¨æ€æ„ŸçŸ¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¸Šä¸‹æ–‡
                real_time_context = self._get_default_context()

            # æ­¥éª¤2ï¼šæ„å»ºè¾“å…¥ï¼ˆåŒ…å«æ„ŸçŸ¥ä¸Šä¸‹æ–‡ï¼‰
            input_dict = {
                "input": message,
                "chat_history": self.conversation_history,
                "context": real_time_context
            }

            # æ­¥éª¤3ï¼šè°ƒç”¨LLMï¼ˆåŸºäºæ„ŸçŸ¥ä¸Šä¸‹æ–‡è¿›è¡Œæ™ºèƒ½å†³ç­–ï¼‰
            try:
                result = await self.agent_executor.ainvoke(input_dict)
            except TypeError:
                # å¦‚æœä¸æ”¯æŒå¼‚æ­¥ï¼Œä½¿ç”¨åŒæ­¥è°ƒç”¨
                result = self.agent_executor.invoke(input_dict)

            # æ­¥éª¤4ï¼šæ›´æ–°å¯¹è¯å†å²
            self.conversation_history.append(HumanMessage(content=message))
            self.conversation_history.append(SystemMessage(content=result["output"]))

            # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…ï¼ˆä½¿ç”¨å¸¸é‡ï¼‰
            if len(self.conversation_history) > MAX_CONVERSATION_HISTORY:
                self.conversation_history = self.conversation_history[-MAX_CONVERSATION_HISTORY:]

            # è¿”å›ç»“æœ
            return {
                "success": True,
                "output": result["output"],
                "tool_calls": getattr(result, 'intermediate_steps', []),
                "context_used": real_time_context,  # è¿”å›ä½¿ç”¨çš„å®æ—¶æ„ŸçŸ¥ä¸Šä¸‹æ–‡
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"åŠ¨æ€æ„ŸçŸ¥å¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def start_monitoring(self, interval: int = 5):
        """å¯åŠ¨æ–‡æ¡£å˜åŒ–ç›‘å¬

        æ³¨æ„ï¼šæ ¹æ® docs/AH32_RULES.md è§„åˆ™ï¼Œæ£€æµ‹åˆ°å˜åŒ–åä¸ä¼šè‡ªåŠ¨è§¦å‘åˆ†æï¼Œ
        è€Œæ˜¯è®°å½•å˜åŒ–å¹¶é€šçŸ¥ç”¨æˆ·ï¼Œç”±ç”¨æˆ·å†³å®šæ˜¯å¦éœ€è¦åˆ†æã€‚
        """
        if self.is_monitoring:
            logger.warning("ç›‘å¬å·²åœ¨è¿è¡Œä¸­")
            return

        self.is_monitoring = True
        self._pending_changes = []
        logger.info(f"å¯åŠ¨æ–‡æ¡£å˜åŒ–ç›‘å¬ï¼Œé—´éš”: {interval}ç§’")

        async def monitor_loop():
            try:
                while self.is_monitoring:
                    # æ£€æµ‹æ–‡æ¡£å˜åŒ–
                    try:
                        from . import get_tool_by_name
                        monitor_tool = get_tool_by_name("monitor_document_changes")
                        if monitor_tool:
                            changes = await monitor_tool.arun()

                            if "æ£€æµ‹åˆ°æ–‡æ¡£å˜åŒ–" in changes:
                                logger.info("æ£€æµ‹åˆ°æ–‡æ¡£å˜åŒ–ï¼Œè®°å½•å˜åŒ–é€šçŸ¥ç”¨æˆ·")
                                # è®°å½•å˜åŒ–ï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤åå¤„ç†
                                self._pending_changes.append({
                                    "time": datetime.now().isoformat(),
                                    "changes": changes
                                })
                    except Exception as e:
                        logger.debug(f"æ£€æµ‹æ–‡æ¡£å˜åŒ–å¤±è´¥: {e}")

                    await asyncio.sleep(interval)

            except asyncio.CancelledError:
                logger.info("æ–‡æ¡£ç›‘å¬ä»»åŠ¡å·²å–æ¶ˆ")
            except Exception as e:
                logger.error(f"ç›‘å¬è¿‡ç¨‹å‡ºé”™: {e}")
            finally:
                self.is_monitoring = False

        self.monitoring_task = asyncio.create_task(monitor_loop())

    def get_pending_changes(self) -> List[Dict]:
        """è·å–å¾…å¤„ç†çš„æ–‡æ¡£å˜åŒ–"""
        return self._pending_changes.copy()

    def clear_pending_changes(self):
        """æ¸…ç©ºå¾…å¤„ç†çš„å˜åŒ–è®°å½•"""
        self._pending_changes = []

    def check_changes_and_notify(self) -> Optional[str]:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å˜åŒ–ï¼Œè¿”å›é€šçŸ¥æ¶ˆæ¯"""
        if not self._pending_changes:
            return None

        count = len(self._pending_changes)
        self._pending_changes = []
        return f"ğŸ“„ æ£€æµ‹åˆ° {count} å¤„æ–‡æ¡£å˜åŒ–ï¼Œè¯·å‘Šè¯‰æˆ‘æ˜¯å¦éœ€è¦åˆ†æè¿™äº›å˜åŒ–çš„å½±å“ã€‚"

    def stop_monitoring(self):
        """åœæ­¢æ–‡æ¡£å˜åŒ–ç›‘å¬"""
        if not self.is_monitoring:
            logger.warning("ç›‘å¬æœªåœ¨è¿è¡Œ")
            return

        self.is_monitoring = False
        if self.monitoring_task:
            self.monitoring_task.cancel()

        logger.info("å·²åœæ­¢æ–‡æ¡£å˜åŒ–ç›‘å¬")

    async def auto_analyze(self, analysis_type: str = "full") -> Dict[str, Any]:
        """æ‰§è¡Œåˆ†æï¼ˆé˜¿è›¤ï¼ˆAH32ï¼‰æ¨¡å¼ï¼‰

        ç®€åŒ–å¤„ç†ï¼Œè®©LLMåŸºäºå®æ—¶ä¸Šä¸‹æ–‡è‡ªä¸»å†³ç­–åˆ†ææ–¹å‘ã€‚
        ä¸é¢„è®¾å›ºå®šæ­¥éª¤ï¼Œç”±LLMæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªä¸»åˆ¤æ–­ã€‚

        Args:
            analysis_type: åˆ†æç±»å‹ï¼ˆä»…ç”¨äºç”¨æˆ·æ„å›¾è¡¨è¾¾ï¼‰
        """
        logger.info(f"å¼€å§‹{analysis_type}åˆ†æ")

        try:
            # ç®€æ´çš„æ„å›¾æè¿°ï¼Œè®©LLMè‡ªä¸»å†³ç­–
            intent = f"è¯·åˆ†æå½“å‰æ–‡æ¡£ï¼Œ{analysis_type}æ¨¡å¼ã€‚"

            # å°†æ„å›¾ä¼ è¾¾ç»™LLMï¼Œè®©LLMåŸºäºå®æ—¶ä¸Šä¸‹æ–‡è‡ªä¸»åˆ¤æ–­
            result = await self.chat(intent)

            return result

        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    async def suggest_analysis(self, context: str = "") -> str:
        """åŸºäºå½“å‰ä¸Šä¸‹æ–‡æ™ºèƒ½å»ºè®®åˆ†ææ–¹å‘ï¼ˆAgentic æ¨¡å¼ï¼‰

        æ ¹æ®å·²æ‰“å¼€çš„æ–‡æ¡£å’Œå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå»ºè®®ç”¨æˆ·å¯èƒ½éœ€è¦çš„åˆ†ææ“ä½œã€‚
        """
        try:
            suggestion_prompt = """
æ ¹æ®å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡å’Œå·²æ‰“å¼€çš„æ–‡æ¡£ï¼Œç®€è¦å»ºè®®ä¸‹ä¸€æ­¥å¯èƒ½éœ€è¦çš„åˆ†ææ–¹å‘ã€‚
è¯·ç›´æ¥ç»™å‡º1-2ä¸ªå»ºè®®ï¼Œä¸è¦é¢„è®¾æ­¥éª¤ã€‚

å»ºè®®æ ¼å¼ï¼š
- å¦‚æœéœ€è¦åˆ†æï¼š"[å…·ä½“å»ºè®®ï¼Œå¦‚ï¼šåˆ†æç¬¬ä¸‰ç« æŠ€æœ¯è¦æ±‚]"
- å¦‚æœä¸éœ€è¦ï¼š""ï¼ˆè¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰

ä¸è¦æä¾›è¯¦ç»†çš„æ“ä½œæ­¥éª¤ï¼Œåªéœ€ç»™å‡ºç®€æ´çš„å»ºè®®ã€‚
"""
            if context:
                suggestion_prompt += f"\nå½“å‰ä¸Šä¸‹æ–‡ï¼š{context}"

            result = await self.chat(suggestion_prompt)
            return result.get("output", "").strip() if result.get("success") else ""

        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆ†æå»ºè®®å¤±è´¥: {e}")
            return ""

    async def quick_question(self, question: str) -> Dict[str, Any]:
        """å¿«é€Ÿå›ç­”é—®é¢˜"""
        try:
            # ä½¿ç”¨answer_questionå·¥å…·ç›´æ¥å›ç­”
            from . import get_tool_by_name
            answer_tool = get_tool_by_name("answer_question")
            if answer_tool:
                answer = await answer_tool.arun(question=question)
                return {
                    "success": True,
                    "answer": answer,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return await self.chat(f"è¯·å›ç­”è¿™ä¸ªé—®é¢˜: {question}")

        except Exception as e:
            logger.error(f"å¿«é€Ÿé—®ç­”å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def get_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            "agent_ready": self.agent_executor is not None,
            "tools_count": len(self.tools),
            "monitoring": self.is_monitoring,
            "conversation_length": len(self.conversation_history),
            "last_activity": datetime.now().isoformat()
        }

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        logger.info("å·²æ¸…ç©ºå¯¹è¯å†å²")

    def get_available_tools(self) -> List[Dict[str, str]]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return [
            {
                "name": tool.name,
                "description": tool.description,
                "category": getattr(tool, 'category', 'unknown')
            }
            for tool in self.tools
        ]

    async def generate_report(self, report_type: str = "summary") -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆAgentic æ¨¡å¼ï¼‰

        æ ¹æ® docs/AH32_RULES.md è§„åˆ™ï¼Œè®© Agent è‡ªä¸»å†³å®šæŠ¥å‘Šå†…å®¹å’Œç»“æ„ã€‚
        """
        try:
            # ç®€æ´çš„æ„å›¾æè¿°ï¼Œä¸é¢„è®¾æŠ¥å‘Šç»“æ„
            intent = f"è¯·ç”Ÿæˆä¸€ä»½{report_type}æŠ¥å‘Šï¼ŒåŸºäºå½“å‰æ‰“å¼€çš„æ–‡æ¡£è¿›è¡Œåˆ†æã€‚"

            result = await self.chat(intent)

            return result

        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }


# å…¨å±€å•ä¾‹å®ä¾‹
_coordinator: Optional[Ah32Coordinator] = None


def get_coordinator(vector_store=None) -> Ah32Coordinator:
    """è·å–å…¨å±€åè°ƒå™¨å®ä¾‹"""
    global _coordinator
    if _coordinator is None or (vector_store is not None and _coordinator.vector_store is None):
        _coordinator = Ah32Coordinator(vector_store)
        _coordinator._create_agent()
    elif vector_store is not None and _coordinator.vector_store is None:
        # å¦‚æœå·²å­˜åœ¨ä½†æ²¡æœ‰vector_storeï¼Œåˆ™æ›´æ–°
        _coordinator.vector_store = vector_store
    return _coordinator


# ä¾¿æ·å‡½æ•°
async def chat(message: str, context: Dict[str, Any] = None, vector_store=None) -> Dict[str, Any]:
    """ä¾¿æ·çš„å¯¹è¯å‡½æ•°"""
    coordinator = get_coordinator(vector_store)
    return await coordinator.chat(message, context)


async def quick_question(question: str, vector_store=None) -> Dict[str, Any]:
    """ä¾¿æ·çš„å¿«é€Ÿé—®ç­”å‡½æ•°"""
    coordinator = get_coordinator(vector_store)
    return await coordinator.quick_question(question)


async def auto_analyze(analysis_type: str = "full", vector_store=None) -> Dict[str, Any]:
    """ä¾¿æ·çš„è‡ªåŠ¨åˆ†æå‡½æ•°"""
    coordinator = get_coordinator(vector_store)
    return await coordinator.auto_analyze(analysis_type)


def start_monitoring(interval: int = 5, vector_store=None):
    """ä¾¿æ·çš„å¯åŠ¨ç›‘å¬å‡½æ•°"""
    coordinator = get_coordinator(vector_store)
    return coordinator.start_monitoring(interval)


def stop_monitoring(vector_store=None):
    """ä¾¿æ·çš„åœæ­¢ç›‘å¬å‡½æ•°"""
    coordinator = get_coordinator(vector_store)
    return coordinator.stop_monitoring()
